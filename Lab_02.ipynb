{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparing_Classifiers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dayanebravo/DSBD/blob/main/Lab_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpMUjVjYQwA7",
        "outputId": "aad2b93b-49bd-41ef-fa6a-274840cd1665"
      },
      "source": [
        "################  NÃO MUDAR NADA #######################\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yVT2YTuZW9J",
        "outputId": "5b71d9ff-548d-4ca5-ccba-89ab68c6f1cc"
      },
      "source": [
        "################  NÃO MUDAR NADA #######################\n",
        "ls /content/drive/MyDrive/data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdigits\u001b[0m/    digTest58k.txt   features.txt  lab1.ipynb  y.csv\n",
            "digits.py  digTrain20k.txt  knn.py        X.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPfpWAYkQPNu"
      },
      "source": [
        "################  NÃO MUDAR NADA #######################\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itWAdyoGY42m",
        "outputId": "fa7efbb1-3310-4cd1-d038-bd71680e575f"
      },
      "source": [
        "################  NÃO MUDAR NADA #######################\n",
        "\tprint (\"Loading data...\")\n",
        "\tX_train, y_train = load_svmlight_file('/content/drive/MyDrive/data/digTrain20k.txt')\n",
        "\tX_test, y_test = load_svmlight_file('/content/drive/MyDrive/data/digTest58k.txt')\n",
        "\tsize = X_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FbG9TJUZ-fw",
        "outputId": "e44e5bd3-af94-4e80-fca8-9044d0686806"
      },
      "source": [
        "################## aqui fazemos as mudanças!!!!!! fiz um bloco pra cada classificador então só comentei nesse primeiro ##########\n",
        "batchsize = 1000    ########## qdo a base for >1mil colocar 1mil aqui / qdo a base for <1mil colocar 100 aqui\n",
        "ini = 0\n",
        "end = batchsize\n",
        "\n",
        "historyLR = []             ##########  abrindo a lista do classificador LR\n",
        "#while(end <= size[0] ):   ########  aqui é a base 20mil\n",
        "#while(end <= 1000 ):   ########  aqui é a base <1mil\n",
        "while(end <= 58646 ):   ########  aqui é a base toda\n",
        "  xt = X_train[0:end]\n",
        "  yt = y_train[0:end]\n",
        "  print (\"Training size... \", end)\t \n",
        "  start_time = time.time()  \n",
        "   \n",
        "  #clf = RandomForestClassifier()\n",
        "  clfLR = linear_model.LogisticRegression()   # esse bloco é para esse classificador!\n",
        "  #clfGNB = GaussianNB()\n",
        "  #clfLDA = LinearDiscriminantAnalysis()\n",
        "  #clfPtron = Perceptron(max_iter=100)\n",
        "   \n",
        "  X_train_dense = xt.toarray()\n",
        "  clfLR.fit(X_train_dense, yt)   #### aqui tem que mudar clf para clfLR\n",
        "  X_test_dense = X_test.toarray()\n",
        "  y_pred = clfLR.predict(X_test_dense)     #### aqui tem que mudar clf para clfLR\n",
        "   \n",
        "  # mostra o resultado do classificador na base de teste\n",
        "  historyLR.append(clfLR.score(X_test_dense, y_test))   #### aqui tem que mudar clf para clfLR / history para historyLR\n",
        "   \n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  end = end + batchsize\n",
        "  print (historyLR)   #### aqui tem que mudar history para historyLR"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size...  1000\n",
            "--- 0.2705216407775879 seconds ---\n",
            "[0.7291204856256182]\n",
            "Training size...  2000\n",
            "--- 0.41630029678344727 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031]\n",
            "Training size...  3000\n",
            "--- 0.5966980457305908 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967]\n",
            "Training size...  4000\n",
            "--- 0.8810510635375977 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826]\n",
            "Training size...  5000\n",
            "--- 1.0730345249176025 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732]\n",
            "Training size...  6000\n",
            "--- 1.4080262184143066 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919]\n",
            "Training size...  7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 1.619258165359497 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313]\n",
            "Training size...  8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 1.8425967693328857 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442]\n",
            "Training size...  9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 2.0470809936523438 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598]\n",
            "Training size...  10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 2.3229169845581055 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913]\n",
            "Training size...  11000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 2.5070905685424805 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848]\n",
            "Training size...  12000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 2.6627378463745117 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472]\n",
            "Training size...  13000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 2.8566999435424805 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902]\n",
            "Training size...  14000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 3.208879232406616 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832]\n",
            "Training size...  15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 3.290374279022217 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013]\n",
            "Training size...  16000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 3.563401937484741 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552]\n",
            "Training size...  17000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 3.702167272567749 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415]\n",
            "Training size...  18000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 3.827803134918213 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167]\n",
            "Training size...  19000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.096154451370239 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346]\n",
            "Training size...  20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.361361742019653 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785]\n",
            "Training size...  21000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.302178621292114 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  22000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.309149265289307 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  23000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.363243103027344 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  24000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.338599920272827 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.354833126068115 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  26000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.328252077102661 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  27000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.431606292724609 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  28000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.317156791687012 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  29000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.343125343322754 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  30000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.37568473815918 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  31000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.326858282089233 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  32000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.3728187084198 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  33000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.333938360214233 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  34000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.3471360206604 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  35000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.3355584144592285 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  36000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.331855773925781 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  37000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.328009128570557 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  38000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.330899953842163 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  39000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.439048528671265 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.358752250671387 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  41000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.3619678020477295 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  42000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.365647077560425 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  43000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.370912551879883 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  44000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.3912036418914795 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  45000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.38847279548645 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  46000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.33337664604187 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  47000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.314489841461182 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  48000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.31335186958313 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  49000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.330669403076172 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.287410259246826 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  51000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.366285085678101 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  52000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.323490381240845 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  53000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.311502456665039 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  54000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.338156461715698 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  55000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.332965850830078 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  56000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.316487550735474 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  57000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 4.3466455936431885 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n",
            "Training size...  58000\n",
            "--- 4.338685989379883 seconds ---\n",
            "[0.7291204856256182, 0.782457456604031, 0.8068922006615967, 0.8138662483374826, 0.8190157896531732, 0.8422057770350919, 0.8632643317532313, 0.8809466971319442, 0.8886369061828598, 0.8960201889301913, 0.895781468471848, 0.8964464754629472, 0.8988507315076902, 0.898253930361832, 0.8982027759779013, 0.9021246120792552, 0.9047675885823415, 0.9080585206152167, 0.9100876445111346, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785, 0.9118268935647785]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOTuoY_rahmw",
        "outputId": "d1002a73-b9c7-4bba-f34d-641f90f9719d"
      },
      "source": [
        "######################### repete tudo do bloco anterior, agora para o próximo classificador e assim por diante #########\n",
        "batchsize = 1000\n",
        "ini = 0\n",
        "end = batchsize\n",
        "\n",
        "historyGNB = []\n",
        "while(end <= 58646 ):\n",
        "  xt = X_train[0:end]\n",
        "  yt = y_train[0:end]\n",
        "  print (\"Training size... \", end)\t \n",
        "  start_time = time.time()  \n",
        "   \n",
        "  #clf = RandomForestClassifier()\n",
        "  #clfLR = linear_model.LogisticRegression() \n",
        "  clfGNB = GaussianNB()\n",
        "  #clfLDA = LinearDiscriminantAnalysis()\n",
        "  #clfPtron = Perceptron(max_iter=100)\n",
        "   \n",
        "  X_train_dense = xt.toarray()\n",
        "  clfGNB.fit(X_train_dense, yt)\n",
        "  X_test_dense = X_test.toarray()\n",
        "  y_pred = clfGNB.predict(X_test_dense) \n",
        "   \n",
        "  # mostra o resultado do classificador na base de teste\n",
        "  historyGNB.append(clfGNB.score(X_test_dense, y_test))\n",
        "   \n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  end = end + batchsize\n",
        "  print (historyGNB)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size...  1000\n",
            "--- 1.0523395538330078 seconds ---\n",
            "[0.6743511918971455]\n",
            "Training size...  2000\n",
            "--- 0.9433872699737549 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648]\n",
            "Training size...  3000\n",
            "--- 0.9282069206237793 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199]\n",
            "Training size...  4000\n",
            "--- 0.9314916133880615 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089]\n",
            "Training size...  5000\n",
            "--- 0.9286909103393555 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629]\n",
            "Training size...  6000\n",
            "--- 0.9412586688995361 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849]\n",
            "Training size...  7000\n",
            "--- 0.9380886554718018 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221]\n",
            "Training size...  8000\n",
            "--- 0.9535877704620361 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653]\n",
            "Training size...  9000\n",
            "--- 0.9372496604919434 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923]\n",
            "Training size...  10000\n",
            "--- 0.9515767097473145 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926]\n",
            "Training size...  11000\n",
            "--- 0.9635322093963623 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523]\n",
            "Training size...  12000\n",
            "--- 0.954848051071167 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089]\n",
            "Training size...  13000\n",
            "--- 0.9497954845428467 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008]\n",
            "Training size...  14000\n",
            "--- 0.956411600112915 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563]\n",
            "Training size...  15000\n",
            "--- 0.951678991317749 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232]\n",
            "Training size...  16000\n",
            "--- 0.9659357070922852 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122]\n",
            "Training size...  17000\n",
            "--- 0.9574737548828125 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397]\n",
            "Training size...  18000\n",
            "--- 0.9949362277984619 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119]\n",
            "Training size...  19000\n",
            "--- 1.0054852962493896 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883]\n",
            "Training size...  20000\n",
            "--- 1.005472183227539 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926]\n",
            "Training size...  21000\n",
            "--- 0.9645998477935791 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  22000\n",
            "--- 0.9827346801757812 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  23000\n",
            "--- 0.9682517051696777 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  24000\n",
            "--- 0.9833724498748779 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  25000\n",
            "--- 0.9674496650695801 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  26000\n",
            "--- 0.9794607162475586 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  27000\n",
            "--- 0.9788174629211426 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  28000\n",
            "--- 0.9876120090484619 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  29000\n",
            "--- 0.9700281620025635 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  30000\n",
            "--- 0.9951982498168945 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  31000\n",
            "--- 0.981548547744751 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  32000\n",
            "--- 0.9858534336090088 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  33000\n",
            "--- 0.9763360023498535 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  34000\n",
            "--- 0.9838063716888428 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  35000\n",
            "--- 0.9768905639648438 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  36000\n",
            "--- 0.9819474220275879 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  37000\n",
            "--- 0.9794857501983643 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  38000\n",
            "--- 0.9770634174346924 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  39000\n",
            "--- 0.9718525409698486 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  40000\n",
            "--- 0.98093581199646 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  41000\n",
            "--- 0.9697821140289307 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  42000\n",
            "--- 0.9985287189483643 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  43000\n",
            "--- 0.9717285633087158 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  44000\n",
            "--- 0.9770975112915039 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  45000\n",
            "--- 0.9693410396575928 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  46000\n",
            "--- 0.9795210361480713 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  47000\n",
            "--- 0.9699974060058594 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  48000\n",
            "--- 0.9876670837402344 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  49000\n",
            "--- 0.978163480758667 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  50000\n",
            "--- 0.9807050228118896 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  51000\n",
            "--- 0.966810941696167 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  52000\n",
            "--- 0.9706935882568359 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  53000\n",
            "--- 0.992372989654541 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  54000\n",
            "--- 0.978257417678833 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  55000\n",
            "--- 0.9755573272705078 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  56000\n",
            "--- 0.9695351123809814 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  57000\n",
            "--- 0.984950065612793 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n",
            "Training size...  58000\n",
            "--- 0.9852664470672607 seconds ---\n",
            "[0.6743511918971455, 0.7820141186099648, 0.8384203526242199, 0.8448999079221089, 0.855096681785629, 0.8693517034409849, 0.8742454728370221, 0.8824813286498653, 0.8873580465845923, 0.889080244176926, 0.887409200968523, 0.8863861132899089, 0.8887051120281008, 0.8854653343791563, 0.884425195239232, 0.8858916209119122, 0.8864372676738397, 0.8880571564983119, 0.8885175459536883, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926, 0.889080244176926]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vulRv5Fba3PY",
        "outputId": "bd4fae6c-a913-473c-eb97-5dbcc9243149"
      },
      "source": [
        "batchsize = 1000\n",
        "ini = 0\n",
        "end = batchsize\n",
        "\n",
        "historyLDA = []\n",
        "while(end <= 58646   ):\n",
        "  xt = X_train[0:end]\n",
        "  yt = y_train[0:end]\n",
        "  print (\"Training size... \", end)\t \n",
        "  start_time = time.time()  \n",
        "   \n",
        "  #clf = RandomForestClassifier()\n",
        "  #clfLR = linear_model.LogisticRegression() \n",
        "  #clfGNB = GaussianNB()\n",
        "  clfLDA = LinearDiscriminantAnalysis()\n",
        "  #clfPtron = Perceptron(max_iter=100)\n",
        "   \n",
        "  X_train_dense = xt.toarray()\n",
        "  clfLDA.fit(X_train_dense, yt)\n",
        "  X_test_dense = X_test.toarray()\n",
        "  y_pred = clfLDA.predict(X_test_dense) \n",
        "   \n",
        "  # mostra o resultado do classificador na base de teste\n",
        "  historyLDA.append(clfLDA.score(X_test_dense, y_test))\n",
        "   \n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  end = end + batchsize\n",
        "  print (historyLDA)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size...  1000\n",
            "--- 0.19664645195007324 seconds ---\n",
            "[0.7873171230774477]\n",
            "Training size...  2000\n",
            "--- 0.24530291557312012 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388]\n",
            "Training size...  3000\n",
            "--- 0.29091691970825195 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074]\n",
            "Training size...  4000\n",
            "--- 0.2985515594482422 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949]\n",
            "Training size...  5000\n",
            "--- 0.36018967628479004 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959]\n",
            "Training size...  6000\n",
            "--- 0.37554407119750977 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906]\n",
            "Training size...  7000\n",
            "--- 0.37862563133239746 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469]\n",
            "Training size...  8000\n",
            "--- 0.4024031162261963 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412]\n",
            "Training size...  9000\n",
            "--- 0.4520750045776367 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118]\n",
            "Training size...  10000\n",
            "--- 0.4695315361022949 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988]\n",
            "Training size...  11000\n",
            "--- 0.49306654930114746 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241]\n",
            "Training size...  12000\n",
            "--- 0.5198087692260742 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133]\n",
            "Training size...  13000\n",
            "--- 0.5399496555328369 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188]\n",
            "Training size...  14000\n",
            "--- 0.5616967678070068 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088]\n",
            "Training size...  15000\n",
            "--- 0.5850403308868408 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822]\n",
            "Training size...  16000\n",
            "--- 0.6183948516845703 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153]\n",
            "Training size...  17000\n",
            "--- 0.6332964897155762 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774]\n",
            "Training size...  18000\n",
            "--- 0.6994791030883789 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204]\n",
            "Training size...  19000\n",
            "--- 0.6995339393615723 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391]\n",
            "Training size...  20000\n",
            "--- 0.7420744895935059 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988]\n",
            "Training size...  21000\n",
            "--- 0.7461898326873779 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  22000\n",
            "--- 0.741417407989502 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  23000\n",
            "--- 0.7468981742858887 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  24000\n",
            "--- 0.7267594337463379 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  25000\n",
            "--- 0.7461240291595459 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  26000\n",
            "--- 0.7438030242919922 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  27000\n",
            "--- 0.7417421340942383 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  28000\n",
            "--- 0.7403275966644287 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  29000\n",
            "--- 0.7342355251312256 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  30000\n",
            "--- 0.7332148551940918 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  31000\n",
            "--- 0.7450222969055176 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  32000\n",
            "--- 0.7303175926208496 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  33000\n",
            "--- 0.7391171455383301 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  34000\n",
            "--- 0.7424192428588867 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  35000\n",
            "--- 0.7580418586730957 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  36000\n",
            "--- 0.7670879364013672 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  37000\n",
            "--- 0.7265317440032959 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  38000\n",
            "--- 0.7253503799438477 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  39000\n",
            "--- 0.759758472442627 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  40000\n",
            "--- 0.740570068359375 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  41000\n",
            "--- 0.7336723804473877 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  42000\n",
            "--- 0.7454688549041748 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  43000\n",
            "--- 0.7286169528961182 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  44000\n",
            "--- 0.7297153472900391 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  45000\n",
            "--- 0.7387962341308594 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  46000\n",
            "--- 0.767176628112793 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  47000\n",
            "--- 0.7197418212890625 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  48000\n",
            "--- 0.7434632778167725 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  49000\n",
            "--- 0.7406883239746094 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  50000\n",
            "--- 0.7577483654022217 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  51000\n",
            "--- 0.7267084121704102 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  52000\n",
            "--- 0.7442827224731445 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  53000\n",
            "--- 0.7388365268707275 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  54000\n",
            "--- 0.7458031177520752 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  55000\n",
            "--- 0.7226564884185791 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  56000\n",
            "--- 0.7383191585540771 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  57000\n",
            "--- 0.7235288619995117 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n",
            "Training size...  58000\n",
            "--- 0.7619805335998535 seconds ---\n",
            "[0.7873171230774477, 0.8732735395423388, 0.8935477270402074, 0.8853630256112949, 0.8905296183882959, 0.9025167956893906, 0.9124407461719469, 0.9207618592913412, 0.9237117620980118, 0.9278552671963988, 0.9260648637588241, 0.9245472837022133, 0.9242233059373188, 0.9220407188896088, 0.9208300651365822, 0.9210517341336153, 0.923149063874774, 0.9250588275415204, 0.9264229444463391, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988, 0.9278552671963988]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcjzSlcCa9dT",
        "outputId": "469e2c57-5ea1-4c6a-f053-25f6dbab7655"
      },
      "source": [
        "batchsize = 1000\n",
        "ini = 0\n",
        "end = batchsize\n",
        "\n",
        "historyPtron = []\n",
        "while(end <= 58646   ):\n",
        "  xt = X_train[0:end]\n",
        "  yt = y_train[0:end]\n",
        "  print (\"Training size... \", end)\t \n",
        "  start_time = time.time()  \n",
        "   \n",
        "  #clf = RandomForestClassifier()\n",
        "  #clfLR = linear_model.LogisticRegression() \n",
        "  #clfGNB = GaussianNB()\n",
        "  #clfLDA = LinearDiscriminantAnalysis()\n",
        "  clfPtron = Perceptron(max_iter=100)\n",
        "   \n",
        "  X_train_dense = xt.toarray()\n",
        "  clfPtron.fit(X_train_dense, yt)\n",
        "  X_test_dense = X_test.toarray()\n",
        "  y_pred = clfPtron.predict(X_test_dense) \n",
        "   \n",
        "  # mostra o resultado do classificador na base de teste\n",
        "  historyPtron.append(clfPtron.score(X_test_dense, y_test))\n",
        "   \n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  end = end + batchsize\n",
        "  print (historyPtron)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size...  1000\n",
            "--- 0.15410399436950684 seconds ---\n",
            "[0.7560788459570985]\n",
            "Training size...  2000\n",
            "--- 0.19620585441589355 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734]\n",
            "Training size...  3000\n",
            "--- 0.22508001327514648 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391]\n",
            "Training size...  4000\n",
            "--- 0.2513155937194824 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231]\n",
            "Training size...  5000\n",
            "--- 0.31339216232299805 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069]\n",
            "Training size...  6000\n",
            "--- 0.29437851905822754 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884]\n",
            "Training size...  7000\n",
            "--- 0.3370492458343506 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972]\n",
            "Training size...  8000\n",
            "--- 0.3724963665008545 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781]\n",
            "Training size...  9000\n",
            "--- 0.4245033264160156 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802]\n",
            "Training size...  10000\n",
            "--- 0.4171888828277588 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811]\n",
            "Training size...  11000\n",
            "--- 0.4927089214324951 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542]\n",
            "Training size...  12000\n",
            "--- 0.5277450084686279 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872]\n",
            "Training size...  13000\n",
            "--- 0.5079290866851807 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341]\n",
            "Training size...  14000\n",
            "--- 0.6155927181243896 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911]\n",
            "Training size...  15000\n",
            "--- 0.730633020401001 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218]\n",
            "Training size...  16000\n",
            "--- 0.7673122882843018 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883]\n",
            "Training size...  17000\n",
            "--- 0.7908051013946533 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813]\n",
            "Training size...  18000\n",
            "--- 0.8783607482910156 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524]\n",
            "Training size...  19000\n",
            "--- 0.8505384922027588 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829]\n",
            "Training size...  20000\n",
            "--- 0.9169490337371826 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768]\n",
            "Training size...  21000\n",
            "--- 0.9171454906463623 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  22000\n",
            "--- 0.8711147308349609 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  23000\n",
            "--- 0.8631589412689209 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  24000\n",
            "--- 0.8790862560272217 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  25000\n",
            "--- 0.8579459190368652 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  26000\n",
            "--- 0.8706929683685303 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  27000\n",
            "--- 0.8916707038879395 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  28000\n",
            "--- 0.8774640560150146 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  29000\n",
            "--- 0.8722569942474365 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  30000\n",
            "--- 0.8897206783294678 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  31000\n",
            "--- 0.8691866397857666 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  32000\n",
            "--- 0.8749308586120605 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  33000\n",
            "--- 0.8757872581481934 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  34000\n",
            "--- 0.9087200164794922 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  35000\n",
            "--- 0.9631519317626953 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  36000\n",
            "--- 0.9515237808227539 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  37000\n",
            "--- 0.9111928939819336 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  38000\n",
            "--- 0.8834600448608398 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  39000\n",
            "--- 0.8850963115692139 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  40000\n",
            "--- 0.895216703414917 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  41000\n",
            "--- 0.902040958404541 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  42000\n",
            "--- 0.8841016292572021 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  43000\n",
            "--- 0.9113619327545166 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  44000\n",
            "--- 0.888371467590332 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  45000\n",
            "--- 0.8784084320068359 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  46000\n",
            "--- 0.884035587310791 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  47000\n",
            "--- 0.8916027545928955 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  48000\n",
            "--- 0.8688867092132568 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  49000\n",
            "--- 0.9109926223754883 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  50000\n",
            "--- 0.8485240936279297 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  51000\n",
            "--- 0.8912620544433594 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  52000\n",
            "--- 0.865253210067749 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  53000\n",
            "--- 0.8698742389678955 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  54000\n",
            "--- 0.8801259994506836 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  55000\n",
            "--- 0.8960185050964355 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  56000\n",
            "--- 0.8758862018585205 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  57000\n",
            "--- 0.913311243057251 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n",
            "Training size...  58000\n",
            "--- 0.867793083190918 seconds ---\n",
            "[0.7560788459570985, 0.8801623299116734, 0.8987654742011391, 0.8517545953688231, 0.8978787982130069, 0.8805204105991884, 0.9073594107014972, 0.890171537700781, 0.9184940149370802, 0.8603485318691811, 0.9384442246700542, 0.9051768236537872, 0.9282474508065341, 0.8981857245165911, 0.9120656140231218, 0.906336323022883, 0.9353238072502813, 0.9339426388841524, 0.9223305937318829, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768, 0.9269856426695768]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbIqGJVC6mnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b223b495-bbe9-40f5-cb0c-f242eb7e67f2"
      },
      "source": [
        "################# para o knn - aqui demora mesmo!\n",
        "batchsize = 1000\n",
        "ini = 0\n",
        "end = batchsize\n",
        "\n",
        "historyKNN = []\n",
        "while(end <= 58646   ):\n",
        "  xt = X_train[0:end]\n",
        "  yt = y_train[0:end]\n",
        "  print (\"Training size... \", end)\t \n",
        "  start_time = time.time()  \n",
        "   \n",
        "  clfKNN = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "   \n",
        "  X_train_dense = xt.toarray()\n",
        "  clfKNN.fit(X_train_dense, yt)\n",
        "  X_test_dense = X_test.toarray()\n",
        "  y_pred = clfKNN.predict(X_test_dense) \n",
        "   \n",
        "  # mostra o resultado do classificador na base de teste\n",
        "  historyKNN.append(clfKNN.score(X_test_dense, y_test))\n",
        "   \n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  end = end + batchsize\n",
        "  print (historyKNN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size...  1000\n",
            "--- 33.86019563674927 seconds ---\n",
            "[0.7917675544794189]\n",
            "Training size...  2000\n",
            "--- 56.7627899646759 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804]\n",
            "Training size...  3000\n",
            "--- 72.38989853858948 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554]\n",
            "Training size...  4000\n",
            "--- 91.40826463699341 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813]\n",
            "Training size...  5000\n",
            "--- 113.99436092376709 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525]\n",
            "Training size...  6000\n",
            "--- 132.4455804824829 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757]\n",
            "Training size...  7000\n",
            "--- 143.1085181236267 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358]\n",
            "Training size...  8000\n",
            "--- 160.33505272865295 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358, 0.9308733758483102]\n",
            "Training size...  9000\n",
            "--- 170.13261556625366 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358, 0.9308733758483102, 0.9345564914913208]\n",
            "Training size...  10000\n",
            "--- 192.56656527519226 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358, 0.9308733758483102, 0.9345564914913208, 0.9382225556730212]\n",
            "Training size...  11000\n",
            "--- 195.29583048820496 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358, 0.9308733758483102, 0.9345564914913208, 0.9382225556730212, 0.9380861439825393]\n",
            "Training size...  12000\n",
            "--- 210.92474222183228 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358, 0.9308733758483102, 0.9345564914913208, 0.9382225556730212, 0.9380861439825393, 0.9386658936670873]\n",
            "Training size...  13000\n",
            "--- 233.8557801246643 seconds ---\n",
            "[0.7917675544794189, 0.8668451386283804, 0.89010333185554, 0.8938376018824813, 0.897742386522525, 0.920454932987757, 0.9269174368243358, 0.9308733758483102, 0.9345564914913208, 0.9382225556730212, 0.9380861439825393, 0.9386658936670873, 0.9386829451283975]\n",
            "Training size...  14000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "O3yTadzBXvHa",
        "outputId": "6f1271a9-cd61-402e-ebea-c544d084a36c"
      },
      "source": [
        "################# graficos dos scores x base de treinamentos #############\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index=(1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000,16000,17000,18000,19000,20000,\n",
        "       21000,22000,23000,24000,25000,26000,27000,28000,29000,30000,31000,32000,33000,34000,35000,36000,37000,38000,39000,40000,\n",
        "       41000,42000,43000,44000,45000,46000,47000,48000,49000,50000,51000,52000,53000,54000,55000,56000,57000,58000) #da base toda\n",
        "\n",
        "#index=(1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000,16000,17000,18000,19000,20000) # da base 20k\n",
        "\n",
        "#index=(100,200,300,400,500,600,700,800,900,1000)  # da base <1mil\n",
        "\n",
        "plt.plot(index,historyKNN,label='KNN')\n",
        "plt.plot(index,historyLDA,label='Linear Discriminant Analysis')\n",
        "plt.plot(index,historyLR,label='Logistic Regression')\n",
        "plt.plot(index,historyGNB,label='Gaussian Naïve Bayes')\n",
        "plt.plot(index,historyPtron,label='Perceptron')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title(\"Score x Classificador\")  # título do gráfico\n",
        "plt.ylabel('Score')  # nome do eixo y\n",
        "plt.xlabel('Base de treinamento')  # nome do eixo x"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Base de treinamento')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "JO0PxUHizlBh",
        "outputId": "297e7658-2b54-437b-f584-250d272e6a97"
      },
      "source": [
        "################# graficos dos tempos x base de treinamentos #############\n",
        "############# coloquei os tempos na mão - enquanto o knn rodava, arrumei o que fazer... hahah #######\n",
        "\n",
        "########### base 20mil #########\n",
        "#tempoKNN=(34.282,56.863,72.550,91.304,114.097,126.991,141.031,159.264,172.583,188.132,205.902,217.848,220.336,228.580,245.795,245.996,254.624,259.542,274.448,289.987)\n",
        "#tempoLDA=(0.186,0.237,0.284,0.304,0.335,0.371,0.382,0.419,0.452,0.476,0.496,0.529,0.564,0.587,0.592,0.631,0.674,0.704,0.697,0.751)\n",
        "#tempoLR=(0.279,0.461,0.604,0.914,1.107,1.363,1.612,1.903,2.048,2.468,2.487,2.645,2.893,3.346,3.275,3.556,3.723,3.840,4.095,4.350)\n",
        "#tempoGNB=(1.136,1.144,1.157,1.130,1.141,1.116,1.147,1.124,1.151,1.124,1.150,1.158,1.138,1.158,1.136,1.044,1.162,1.166,1.165,1.061)\n",
        "#tempoPtron=(0.186,0.237,0.284,0.304,0.335,0.371,0.382,0.419,0.452,0.476,0.496,0.529,0.564,0.587,0.592,0.631,0.674,0.697,0.704,0.751)\n",
        "########################################################\n",
        "\n",
        "#########33 base <1mil  ##########\n",
        "tempoLR=(0.140,0.145,0.160,0.182,0.185,0.209,0.214,0.222,0.255,0.265)\n",
        "tempoGNB=(0.912,0.915,0.917,0.929,0.931,0.933,0.938,0.940,0.948,0.948)\n",
        "tempoLDA=(0.165,0.169,0.179,0.182,0.192,0.193,0.201,0.210,0.213,0.217)\n",
        "tempoPtron=(0.114,0.133,0.139,0.141,0.142,0.148,0.149,0.157,0.169,0.177)\n",
        "tempoKNN=(6.267,9.208,12.837,15.058,20.104,22.349,24.190,26.427,28.550,33.998)\n",
        "########################################################\n",
        "\n",
        "#plt.plot(index,tempoKNN,label='KNN')   # tirei pra comparar os tempos dos outros pq o knn tá muito demorado\n",
        "plt.plot(index,tempoLDA,label='Linear Discriminant Analysis')\n",
        "plt.plot(index,tempoLR,label='Logistic Regression')\n",
        "plt.plot(index,tempoGNB,label='Gaussian Naïve Bayes')\n",
        "plt.plot(index,tempoPtron,label='Perceptron')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title(\"Tempo x Classificador\")  # título do gráfico\n",
        "plt.ylabel('Tempo')  # nome do eixo y\n",
        "plt.xlabel('Base de treinamento')  # nome do eixo x"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Base de treinamento')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}